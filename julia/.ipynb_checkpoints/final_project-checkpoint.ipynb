{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normal Naive Bayes\n",
    "##Preprocess the Data\n",
    "##Generate negative review\n",
    "##open mega negative doc\n",
    "f = open(\"NegVocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create negative dictionary with tf\n",
    "NegDictionary = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    #tf\n",
    "    tempTF = parse(tempArray[2])\n",
    "    NegDictionary[tempWord] = tempTF\n",
    "end\n",
    "##build postive dictionary\n",
    "##open mega positive doc\n",
    "f = open(\"PosVocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create Post dictionary with tf\n",
    "PosDictionary = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    #tf\n",
    "    tempTF = parse(tempArray[2])\n",
    "    PosDictionary[tempWord] = tempTF\n",
    "end\n",
    "##build dictionary\n",
    "##open vocab files\n",
    "f = open(\"vocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "lines\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create dictionary with tf\n",
    "Vocab = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    tempTF = parse(tempArray[2])\n",
    "    Vocab[tempWord] = tempTF\n",
    "end\n",
    "##########################################################################\n",
    "#Create Positive Negative words dictionary\n",
    "f = open(\"posnegwords.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "#dictionary of postive words and negative words\n",
    "PosNegWords = Dict()\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "    lines[i] = replace(lines[i],\"\\t\",\"  \")\n",
    "    lines[i] = replace(lines[i],\"  \",\" \")\n",
    "    tempArray = split(lines[i])\n",
    "    for w in tempArray\n",
    "        if(w == \"Negativ\")\n",
    "            tempArray[1] = replace(tempArray[1],\"#\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"1\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"2\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"3\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"4\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"5\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"6\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"7\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"8\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"9\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"10\",\"\")\n",
    "            PosNegWords[lowercase(tempArray[1])] = -1\n",
    "        end\n",
    "        if(w == \"Positiv\")\n",
    "            tempArray[1] = replace(tempArray[1],\"#\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"1\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"2\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"3\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"4\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"5\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"6\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"7\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"8\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"9\",\"\")\n",
    "            tempArray[1] = replace(tempArray[1],\"10\",\"\")\n",
    "            PosNegWords[lowercase(tempArray[1])] = 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binarized Naive Bayes\n",
    "##Preprocess the Data\n",
    "##Generate negative review\n",
    "##open mega negative doc\n",
    "f = open(\"NegVocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create negative dictionary with tf\n",
    "NegDictionary = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    #df\n",
    "    tempDF = parse(tempArray[3])\n",
    "    NegDictionary[tempWord] = tempDF\n",
    "end\n",
    "##build postive dictionary\n",
    "##open mega positive doc\n",
    "f = open(\"PosVocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create Post dictionary with tf\n",
    "PosDictionary = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    #df\n",
    "    tempDF = parse(tempArray[3])\n",
    "    PosDictionary[tempWord] = tempDF\n",
    "end\n",
    "##build dictionary\n",
    "##open vocab files\n",
    "f = open(\"vocab.txt\")\n",
    "lines = readlines(f)\n",
    "close(f)\n",
    "lines\n",
    "#chomp each line\n",
    "for i = 1:length(lines)\n",
    "    lines[i] = chomp(lines[i])\n",
    "end\n",
    "#create dictionary with tf\n",
    "Vocab = Dict()\n",
    "for i = 1:length(lines)\n",
    "    tempArray = split(lines[i])\n",
    "    tempWord = \"\"\n",
    "    tempWord = tempArray[1]\n",
    "    #df\n",
    "    tempDF = parse(tempArray[3])\n",
    "    Vocab[tempWord] = tempDF\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generateReview (generic function with 1 method)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in review\n",
    "function generateReview(fileName)\n",
    "    f = open(fileName)\n",
    "    lines = readlines(f)\n",
    "    close(f)\n",
    "    #chomp each line\n",
    "    review = \"\"\n",
    "    for i = 1:length(lines)\n",
    "        tempString = lines[i]\n",
    "        tempString = chomp(tempString)\n",
    "        tempString = replace(tempString,\"\\\"\",\"\")\n",
    "        tempString = replace(tempString,\"(\",\"\")\n",
    "        tempString = replace(tempString,\")\",\"\")\n",
    "        tempString = replace(tempString,\".\",\"\")\n",
    "        tempString = replace(tempString,\",\",\"\")\n",
    "        tempString = replace(tempString,\":\",\"\")\n",
    "        tempString = replace(tempString,\";\",\"\")\n",
    "        tempString = replace(tempString,\"  \",\" \")\n",
    "        review = review * tempString\n",
    "    end\n",
    "    return review\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#After the above step 4 dictionaries was created\n",
    "NegDictionary;\n",
    "PosDictionary;\n",
    "Vocab;\n",
    "PosNegWords;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute Parameter Estimation\n",
    "# P(w|class)\n",
    "# for (k,tf) in Vocab\n",
    "#     print(tf)\n",
    "#     break\n",
    "# end\n",
    "function ComputeParaEst(NegDictionary,PosDictionary,Vocab)\n",
    "    VocabSize = length(Vocab)\n",
    "    termGNeg = Dict()\n",
    "    termGPos = Dict()\n",
    "    NegSize = 0 \n",
    "    PosSize = 0 \n",
    "    for (k,tf) in NegDictionary\n",
    "        NegSize = NegSize + tf\n",
    "    end\n",
    "    \n",
    "    for (k,tf) in PosDictionary\n",
    "        PosSize = PosSize + tf\n",
    "    end\n",
    "    \n",
    "    for (k,tf) in Vocab\n",
    "        nk1 = try NegDictionary[k] catch 0 end #find neg words\n",
    "        nk2 = try PosDictionary[k] catch 0 end #find pos words\n",
    "        #upshoot\n",
    "#         NP = try PosNegWords[w] catch 0 end\n",
    "#         if (NP != 0)\n",
    "#             alpha = 10 #upshoot parameter\n",
    "#             if (NP == 1)\n",
    "# #                 nk1 = nk1/alpha\n",
    "#                 nk2 = nk2*alpha\n",
    "#             end #upshoot positve words\n",
    "#             if (NP == -1) \n",
    "#                 nk1 = nk1*alpha\n",
    "# #                 nk2 = nk2/alpha \n",
    "#             end #upshoot negative words\n",
    "#         end\n",
    "        pwc1 =(nk1+1)/(NegSize+VocabSize) #prob word given class 1 \n",
    "        pwc2 =(nk2+1)/(PosSize+VocabSize) #prob word given class 2\n",
    "        termGNeg[k] = pwc1\n",
    "        termGPos[k] = pwc2\n",
    "    end\n",
    "    return termGNeg,termGPos\n",
    "end\n",
    "termGNeg,termGPos = ComputeParaEst(NegDictionary,PosDictionary,Vocab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveBayes (generic function with 1 method)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multinomial Naive\n",
    "function NaiveBayes(review,termGNeg,termGPos,NegDictionary,PosDictionary,Vocab)\n",
    "    #VocabSize\n",
    "    VocabSize = length(termGNeg)\n",
    "    #break down review into word.\n",
    "    listOfWord = split(review)\n",
    "    #prior \n",
    "    pN = 1/2\n",
    "    pP = 1/2\n",
    "    scoreN = log10(pN)\n",
    "    scoreP = log10(pP)\n",
    "    #spagetti code, compute negvocab size\n",
    "    NegSize = 0 \n",
    "    PosSize = 0 \n",
    "    for (k,tf) in NegDictionary\n",
    "        NegSize = NegSize + tf\n",
    "    end\n",
    "    \n",
    "    for (k,tf) in PosDictionary\n",
    "        PosSize = PosSize + tf\n",
    "    end\n",
    "    #compute\n",
    "    for w in listOfWord\n",
    "        wN = try termGNeg[w] catch 1/(NegSize+VocabSize) end #dealing with unknown words\n",
    "        wP = try termGPos[w] catch 1/(PosSize+VocabSize) end#dealing with unknown words\n",
    "        scoreN = scoreN + log10(wN) \n",
    "        scoreP = scoreP + log10(wP) \n",
    "    end\n",
    "    if (scoreN > scoreP) \n",
    "        return \"-\"\n",
    "    else    \n",
    "        return \"+\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarizedNaiveBayes (generic function with 2 methods)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary multinomial Naive Bayes\n",
    "function BinarizedNaiveBayes(review,termGNeg,termGPos,NegDictionary,\n",
    "                             PosDictionary,Vocab,PosNegWords)\n",
    "    #VocabSize\n",
    "    VocabSize = length(termGNeg)\n",
    "    #break down review into word.\n",
    "    listOfWord = split(review)\n",
    "    reviewDict = Dict()\n",
    "    #for each word review\n",
    "    for w in  listOfWord\n",
    "        reviewDict[w] = 1\n",
    "    end\n",
    "    #prior \n",
    "    pN = 1/2\n",
    "    pP = 1/2\n",
    "    scoreN = log10(pN)\n",
    "    scoreP = log10(pP)\n",
    "    #spagetti code, compute negvocab size\n",
    "    NegSize = 0 \n",
    "    PosSize = 0 \n",
    "    for (k,tf) in NegDictionary\n",
    "        NegSize = NegSize + tf\n",
    "    end\n",
    "    \n",
    "    for (k,tf) in PosDictionary\n",
    "        PosSize = PosSize + tf\n",
    "    end\n",
    "    \n",
    "    #compute\n",
    "    for (w,v) in reviewDict\n",
    "        wN = try termGNeg[w] catch 1/(NegSize+VocabSize) end #dealing with unknown words\n",
    "        wP = try termGPos[w] catch 1/(PosSize+VocabSize) end #dealing with unknown words\n",
    "        NP = try PosNegWords[w] catch 0 end\n",
    "        scoreN = scoreN + log10(wN) \n",
    "        scoreP = scoreP + log10(wP) \n",
    "    end\n",
    "    if (scoreN > scoreP) \n",
    "        return \"-\"\n",
    "    else    \n",
    "        return \"+\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NegCount = 0\n",
    "PosCount = 0\n",
    "for i = 1:700\n",
    "    fileName =\"test_set\\\\pos\\\\pos ($i).txt\"\n",
    "    try\n",
    "        review = generateReview(fileName)\n",
    "        r = BinarizedNaiveBayes(review,termGNeg,termGPos,NegDictionary,PosDictionary,Vocab)\n",
    "        if (r == \"+\")\n",
    "            PosCount +=1\n",
    "        else\n",
    "            NegCount +=1\n",
    "        end\n",
    "    catch\n",
    "        println(i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PosCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NegCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NegCount = 0\n",
    "PosCount = 0\n",
    "for i = 1:700\n",
    "    fileName =\"test_set\\\\neg\\\\neg ($i).txt\"\n",
    "    try\n",
    "        review = generateReview(fileName)\n",
    "        r = BinarizedNaiveBayes(review,termGNeg,termGPos,NegDictionary,PosDictionary,Vocab)\n",
    "        if (r == \"+\")\n",
    "            PosCount +=1\n",
    "        else\n",
    "            NegCount +=1\n",
    "        end\n",
    "    catch\n",
    "        println(i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NegCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PosCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1:1000\n",
    "    fileName =\"positive\\\\positive ($i).txt\"\n",
    "    #read\n",
    "    f = open(fileName)\n",
    "    tempDoc = readall(f)\n",
    "    tempDoc = \"<DOC>\\n<DOCNO>p$i</DOCNO>\\n<TEXT>\\n\"*tempDoc*\"</TEXT>\\n</DOC>\\n\"\n",
    "    close(f)\n",
    "    #write\n",
    "    f = open(\"TrecPositive\\\\p$i.txt\",\"w\")\n",
    "    write(f,tempDoc)\n",
    "    close(f)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1:1000\n",
    "    fileName =\"negative\\\\negative ($i).txt\"\n",
    "    #read\n",
    "    f = open(fileName)\n",
    "    tempDoc = readall(f)\n",
    "    tempDoc = \"<DOC>\\n<DOCNO>n$i</DOCNO>\\n<TEXT>\\n\"*tempDoc*\"</TEXT>\\n</DOC>\\n\"\n",
    "    close(f)\n",
    "    #write\n",
    "    f = open(\"TrecNegative\\\\n$i.txt\",\"w\")\n",
    "    write(f,tempDoc)\n",
    "    close(f)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"chinese\" => 1\n",
       "  \"nam\"     => 1\n",
       "  \"viet\"    => 1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string  = \"chinese chinese viet nam nam viet\"\n",
    "s = split(string)\n",
    "d = Dict()\n",
    "for w in s\n",
    "    d[w] = 1\n",
    "end\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese\n",
      "nam\n",
      "viet\n"
     ]
    }
   ],
   "source": [
    "for (k,a) in d\n",
    "    println(k)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: KeyError: Colon() not found\nwhile loading In[80], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: KeyError: Colon() not found\nwhile loading In[80], in expression starting on line 1",
      "",
      " in getindex at dict.jl:718"
     ]
    }
   ],
   "source": [
    "\"chinese\" in d[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.3",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
